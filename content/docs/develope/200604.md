---
title: "google cloud function을 이용한 크롤러 2"
date: 2020-06-04T19:18:18+09:00
# bookFlatSection: false
# bookToc: true
# bookHidden: false
# bookCollapseSection: false
# bookComments: true
---

이전글

> 파이썬 + request + beautifulsoup를 구글 클라우드 펑션에 구현하기
>
> https://jdh-earthling.github.io/docs/developernote/200505/
>
> google cloud function을 이용한 크롤러
>
> https://jdh-earthling.github.io/docs/developernote/200525/
>

  		  

  		   

google cloud function이 어떻게 작동하는지 대충 파악했고 

requests도 사용할 줄 아니

외부로부터 http요청을 받으면 http요청에 포함된 타겟url값을 가지고 크롤링을 하는 서버를 만들 수 있다 ㅇㅇ 

그러기 위해서는

1. **타겟 url을 포함하는 http 요청을 서버가 읽을 수 있는 형태로 서버에 날린다.**
2. **http요청을 해석하고 타겟 url 크롤링 수행**
3. **크롤링한 데이터를 return한다**

​      

짧게 기록하자면

1. **request가 읽을 수 있는 형태로 http 요청 날리기**

     

   get을 사용할 수도 있고, post를 사용할 수도 있는데 그 둘의 차이는 다음 링크에 잘 설명되어있다.

   https://blog.outsider.ne.kr/312

> ​		GET은 가져오는 것이고 POST는 수행하는 것입니다.

​		라고하는데, 그렇다면 우리의 경우는 어떤걸 써야하나

​		  

​		크롤링서버의 주소가 server.com/function이라고 했을 떄 

​		GET을 사용할 경우 클라이언트가 요청하는 http 프로토콜은 다음과 같다.

​		server.com/function?url=https://blog.ahahahah.com/blabla/21012030320

​		클라이언트가 받게될 정보는 실제로 위의 주소를 가진 기존에 생성된 페이지에서 오는게 아니라, 위의 http 요청에서 ?url= 뒤에있는 타겟url에서 서버가 정보를 크롤링해오는 것이기 때문에

​		POST를 사용하는 것이 맞다		  

​		  

2. **post로 날라온 http request에서 target url 값 읽고 크롤링**

   쉬움 ㅇㅇ (해놓고보면 ㅇㅇㅇ) beautifulsoap 등 파이썬 크롤링 모듈 많으니 쓰면 됨.

   문제는 크롤링 알고리즘이랑 방법론

  		  

3. **크롤링한 데이터 json으로 리턴**

   파이썬 dict 사용해서 크롤링한 데이터 정리하고 그대로 리턴하면 됨다... 

