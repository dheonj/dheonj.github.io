<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>개발 기록 Developer Note on My New Hugo Site</title>
    <link>http://example.org/docs/develope/</link>
    <description>Recent content in 개발 기록 Developer Note on My New Hugo Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 Jan 2021 23:11:51 +0900</lastBuildDate><atom:link href="http://example.org/docs/develope/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>도서 검색 api - 네이버, kakao (&#43;파이썬에서 xml 파싱)</title>
      <link>http://example.org/docs/develope/210101/</link>
      <pubDate>Fri, 01 Jan 2021 23:11:51 +0900</pubDate>
      
      <guid>http://example.org/docs/develope/210101/</guid>
      <description>네이버, 카카오 둘 다 도서 검색 api를 제공한다.
isbn 값을 넣어주면, 책에대한 정보를 서버에 요청하고 받아오는 코드를 작성함.
결과적으로 카카오껄 썼는데, 이유는 출력값이 json이고 개발자 페이지에서 바로 api를 테스트 해볼 수 있어서.
그리고 책 정보가 둘다 짤리긴 하는데 카카오가 조금 더 길다&amp;hellip;
책정보 안짜르고 제공해줄수있을지 문의해봐야겠다.
카카오: https://developers.kakao.com/docs/latest/ko/daum-search/dev-guide#search-book
네이버: https://developers.naver.com/docs/search/book/
둘 다 client key를 발급받아야하는데, 로그인하고 몇가지 정보만 입력하면 바로 발급된다.
카카오
import requests import json &amp;#39;&amp;#39;&amp;#39; curl -X GET &amp;#34;https://dapi.</description>
    </item>
    
    <item>
      <title>Booklist using spreadsheet(&#43;Google Apps Script), 구글 스크립트로 작성한 북리스트 자동 관리 프로그램</title>
      <link>http://example.org/docs/develope/200907_google_apps_script_project_booklist/</link>
      <pubDate>Mon, 07 Sep 2020 01:32:38 +0900</pubDate>
      
      <guid>http://example.org/docs/develope/200907_google_apps_script_project_booklist/</guid>
      <description>https://dheonj.github.io/docs/develope/200812/
여기에서 대충 얘기한 독서리스트 얘기 이어서..
구글 스프레드시트로 만든 독서 리스트 관리 프로그램 lite 버전.
다음 링크에서 구경할 수 있음. 이사람은 이런책을 리스트에 담가놨구나.
https://docs.google.com/spreadsheets/d/1bHBjwDHrYAHdpVS6u-1Lsywp4F4aL87wh8mhYNGNBlw/edit?usp=sharing
본인 드라이브에 복사하면 사용 가능하다.
읽을 책, 읽은 책 이렇게 두 개의 시트로 구성되어있고, 몇가지 자동 기능이 있음
  각각의 리스트 맨 위 빈칸에 제목을 입력하면 자동으로 아래 리스트에 추가됨.
  체크박스를 클릭하면 읽은책 리스트로 옮겨지거나 리스트에서 삭제할 수도 있음.
  (std 버전 한정) 독후감을 쓸 수 있도록 자동으로 docs 파일을 생성하고 오픈함</description>
    </item>
    
    <item>
      <title>hugo 블로그 구글 서치 콘솔 등록</title>
      <link>http://example.org/docs/develope/200824/</link>
      <pubDate>Mon, 24 Aug 2020 22:44:48 +0900</pubDate>
      
      <guid>http://example.org/docs/develope/200824/</guid>
      <description>깃헙 블로그에 막 신나게 글을 썼는데 검색에 노출이 안되면 은근히 섭섭하다.
뭐,, 그런것보다도 정보를 공유하려고 하는 짓들이니 구글검색에 나오도록 해야함.
https://hahafamilia.github.io/howto/hugo-staticgen/ 이분 글을 참조 해서 했다 ㅇㅇㅇ 짧게 정리하면
  블로그가 검색 노출이 되도록 설정
# config.toml 파일에 아래 내용 추가enableRobotsTXT = true[outputs]home = [&amp;quot;HTML&amp;quot;, &amp;quot;RSS&amp;quot;, &amp;quot;JSON&amp;quot;][sitemap]changefreq = &amp;quot;weekly&amp;quot;filename = &amp;quot;sitemap.xml&amp;quot;  https://search.google.com/ 에 블로그 주소 등록
  여기에서 add property하면 끝나는게 아니라,,, (오늘알았음 )</description>
    </item>
    
    <item>
      <title>hugo 블로그 구축할때 레포가 2개 필요한 이유</title>
      <link>http://example.org/docs/develope/200823/</link>
      <pubDate>Sun, 23 Aug 2020 16:19:41 +0900</pubDate>
      
      <guid>http://example.org/docs/develope/200823/</guid>
      <description>휴고 블로그 구축할때 깃헙 레포가 2개 필요하다.
하나는 블로그의 모든 소스가 들어가있는 폴더고 (hugo/blog)
다른 하나는 거기에 있는 소스들을 publish해서 블로그로 보여줄 수 있는 형태로 바뀐 html위주 파일이 저장되는 레포 ㅇㅇㅇ (hugo/blog/public)
그 개념을 잘 몰라서 지금까지 헷갈렸음,,</description>
    </item>
    
    <item>
      <title>구글 app script 에서 installable trigger 활성화하기</title>
      <link>http://example.org/docs/develope/200814/</link>
      <pubDate>Fri, 14 Aug 2020 00:31:34 +0900</pubDate>
      
      <guid>http://example.org/docs/develope/200814/</guid>
      <description>구글 app script에서 기본으로 제공하는 심플 트리거는 몇가지가 있다.
(https://developers.google.com/apps-script/guides/triggers 참조)
파일이 열릴 때 작동하는 onOpen(e), 파일을 수정할 때마다 작동하는 onEdit(e) 등
자세한 설명은 위의 주소에 들어가면 적혀있다. 괄호 안에 들어가 있는 e는 트리거 오브젝트라고 불르는데, 겁먹지말고 예제를 보다보면 이해가 간다.
function onEdit(e) { var range = e.range; range.setValue(&amp;#39;Last modified: &amp;#39; + new Date()); } 내용을 조금 수정했는데, 이런식으로 사용한다. 사용자가 스프레드시트를 수정했을 때 트리거가 작동하고 여기서 트리거 오브젝트 e는 그 이벤트에 대한 정보를 담고있다.</description>
    </item>
    
    <item>
      <title>구글 스프레드 시트 &#43; app script 이용해서 독서 리스트 관리하기</title>
      <link>http://example.org/docs/develope/200812/</link>
      <pubDate>Wed, 12 Aug 2020 22:56:32 +0900</pubDate>
      
      <guid>http://example.org/docs/develope/200812/</guid>
      <description>이것은 장기 프로젝트인 거시다.
구글 드라이브를 저장공간으로도 많이 썼지만, 스크립트를 작성해서 캘린더 일정을 스프레드시트와 연동하는 것도 만들어보고, 학과 근로 업무할때도 사용했다.
개인적으로 독서리스트 관리 시트를 만들어서 써오다가 코드를 너무 더럽게 짜서,, 조금 개선을 시켰다.. 물론 누구의 리뷰도 받지 않았음,, (대충 더럽다는 얘기)
리스트 관리하고 업데이트하는일이 쉬울것같은데,, 어렵더라.
​
먼저 인터페이스를 짜 보았다. 일단 읽을책/읽은책 리스트와 거기에 자동으로 추가/삭제하는 기능, 장르별로 대략적인 통계를 보여주는 정도로 화면구성을 했다.
추가적인 기능들을 몇개 넣으려 했는데, 프리징 시킨 행이나 열 개수가 늘어날수록 아무래도 화면이 너무 답답해보여서 기본 목록 관리 기능만 적용하기로 하고 화면도 수정했다.</description>
    </item>
    
    <item>
      <title>LG그램에 리눅스 20.04 설치하기</title>
      <link>http://example.org/docs/develope/200726/</link>
      <pubDate>Sun, 26 Jul 2020 18:28:08 +0900</pubDate>
      
      <guid>http://example.org/docs/develope/200726/</guid>
      <description>2021.1.2 업뎃
다 필요없고 WSL2 (Windows Subsystem for Linux 2) 설치 후 그 환경에서 ROS 깔고 이용하는게 최고!!
오 생각보다 간단하게 설치완료. 오류도 없이 설치해버렸으요.
내 컴터는 lg 그램 15Z990-HA7BK에 윈도우10 설치되어있었고,
ssd는 256, 512 두개 사용중. C드라이브 (256)에 윈도우 설치. 나는 D드라이브(512)에 우분투 설치 완료.
설치 USB 준비
 USB 포맷 (FAT32) 우분투 설치파일 (.iso) 다운로드 (오늘 날짜 기준 ubuntu-20.04-desktop-amd64.iso) 다운받은 iso파일을 etcher나 뭐 이런거 사용하지 않고 그냥 우클릭해서 usb에 압축해제  컴터 준비</description>
    </item>
    
    <item>
      <title>인코딩, 디코딩 정리. 인스타그램 oembed 데이터 디코딩하기</title>
      <link>http://example.org/docs/develope/200723_b/</link>
      <pubDate>Thu, 23 Jul 2020 21:27:59 +0900</pubDate>
      
      <guid>http://example.org/docs/develope/200723_b/</guid>
      <description>이것도 맨날 헷갈리는 개념
출처: https://medium.com/@chrisjune_13837/%EC%9D%B8%EC%BD%94%EB%94%A9%EA%B3%BC-%EB%94%94%EC%BD%94%EB%94%A9-87006cf8dee2
인코딩: 문자열을 바이트로 변환#  바이트 코드는 utf-8, euc-kr, ascii 등의 형식을 가짐
  파이썬은 문자열을 유니코드로 처리 ㅇㅇ
  즉 파이썬에서 인코딩이란, 유니코드 &amp;ndash;&amp;gt; utf-8, euc-kr, ascii#디코딩은 그 반대: 바이트를 문자열로 변환#utf-8, euc-kr, ascii &amp;ndash;&amp;gt; 유니코드#인스타그램 oembed가 리턴해주는건 json데이터인데, 이걸 모르고
받아온 바이트데이터를 utf-8로 인코딩 euc로 인코딩해보고 인코딩한거에서 \\u0000 없애보고 난리부르스를,,,</description>
    </item>
    
    <item>
      <title>hugo 명령어 정리, git 배쉬에서 .md파일 바로 실행하기</title>
      <link>http://example.org/docs/develope/200723/</link>
      <pubDate>Thu, 23 Jul 2020 21:07:19 +0900</pubDate>
      
      <guid>http://example.org/docs/develope/200723/</guid>
      <description>맨날 까먹어서 ㅇㅇㅇ
자주쓰는거만 정리
$ hugo server -D$ hugo new docs/develope/200723.md$ ./deploy.shzzzz
그리고 docs아래 사용하는 폴더는
book / develope / diary / paper
이렇게 있음
git에서 방금 생성한 마크다운 파일을 바로 실행하려면 ㅇㅇㅇ
https://support.typora.io/Use-Typora-From-Shell-or-cmd/
$ start ./content/docs/develope/200723.md크,,,
사실 사진넣거나 이런거 아니면 거의 이정도만 쓴다,,
그래도 start 명령어 오늘 처음 알았음
뿌-듯</description>
    </item>
    
    <item>
      <title>추천 시스템 만들기 building a recommendation system 0</title>
      <link>http://example.org/docs/develope/200618/</link>
      <pubDate>Thu, 18 Jun 2020 00:02:14 +0900</pubDate>
      
      <guid>http://example.org/docs/develope/200618/</guid>
      <description>sns 타임라인 피드 추천 시스템을 구현해보려고 한다.
신문기사등 다른 url을 퍼온 포스팅을 대상으로 한다.
A라는 기사가 있고 B라는 블로그 글이 있고 C라는 외부홈페이지 글이 있을 때,
어떤 알고리즘으로 이 기사들을 유저들의 타임라인에 노출시킬것인가?
그러기위해서 먼저 적절한 데이터셋을 찾아보자
다행히 내 쓰임새와 딱 맞는 데이터를 찾았다.
​
데이터 가공이 먼저 필요하다.
​
원본 데이터는 총 2개의 파일로 구성됨.
shared_articles : 공유된 기사에 대한 정보. url, 업로드한 사람에 대한 정보, 해당 게시물에 해당된 id, 언어 등</description>
    </item>
    
    <item>
      <title>google cloud function을 이용한 크롤러 2</title>
      <link>http://example.org/docs/develope/200604/</link>
      <pubDate>Thu, 04 Jun 2020 19:18:18 +0900</pubDate>
      
      <guid>http://example.org/docs/develope/200604/</guid>
      <description>이전글
 파이썬 + request + beautifulsoup를 구글 클라우드 펑션에 구현하기
https://jdh-earthling.github.io/docs/developernote/200505/
google cloud function을 이용한 크롤러
https://jdh-earthling.github.io/docs/developernote/200525/
 google cloud function이 어떻게 작동하는지 대충 파악했고
requests도 사용할 줄 아니
외부로부터 http요청을 받으면 http요청에 포함된 타겟url값을 가지고 크롤링을 하는 서버를 만들 수 있다 ㅇㅇ
그러기 위해서는
 타겟 url을 포함하는 http 요청을 서버가 읽을 수 있는 형태로 서버에 날린다. http요청을 해석하고 타겟 url 크롤링 수행 크롤링한 데이터를 return한다  ​</description>
    </item>
    
    <item>
      <title>google cloud function을 이용한 크롤러</title>
      <link>http://example.org/docs/develope/200525/</link>
      <pubDate>Mon, 25 May 2020 23:04:38 +0900</pubDate>
      
      <guid>http://example.org/docs/develope/200525/</guid>
      <description>이전 글
https://jdh-earthling.github.io/docs/developernote/200505/
 함수서버 url을 server.com/function 이라고 했을때
클라이언트가 server.com/function?url=https://blog.naver.com/blabla/21012030320
에 접속을 하면 (요청을 하면)
서버는 위 url 주소에 해당하는 (https://blog.naver.com/blabla/21012030320) 페이지의 이런저런 소스들을 가져온다.
 이어서,,
def hello_world(request): &amp;#34;&amp;#34;&amp;#34;Responds to any HTTP request. Args: request (flask.Request): HTTP request object. Returns: The response text or any set of values that can be turned into a Response object using `make_response &amp;lt;http://flask.pocoo.org/docs/1.0/api/#flask.Flask.make_response&amp;gt;`. &amp;#34;&amp;#34;&amp;#34; request_json = request.get_json() if request.args and &amp;#39;message&amp;#39; in request.</description>
    </item>
    
    <item>
      <title>파이썬 &#43; requests &#43; beautifulsoup 를 구글 클라우드 펑션에 구현하기</title>
      <link>http://example.org/docs/develope/200505/</link>
      <pubDate>Tue, 05 May 2020 22:13:59 +0900</pubDate>
      
      <guid>http://example.org/docs/develope/200505/</guid>
      <description>Google cloud function을 사용해서, 크롤링 서버를 하나 만들었음.
함수서버 url을 server.com/function 이라고 했을때
클라이언트가 server.com/function?url=https://blog.ahahahah.com/blabla/21012030320
에 접속을 하면 (요청을 하면)
서버는 위 url 주소에 해당하는 (https://blog.ahahahah.com/blabla/21012030320) 페이지의 이런저런 소스들을 가져온다.
매우 간단한 기능을 구현했음에도, 리비전 횟수가 70번에 이를만큼 삽질을 많이 해서 기록으로 남김&amp;hellip;
누군가에게는 유용했으면 하는 마음이랄까나
한 일 / 과정# 구글 클라우드 펑션 서버를 연다. 파이썬으로 예제를 돌려봄. url에 따라서 다른 출력을 내는 것을 확인. 서버 동작 환경에 beautifulsoup 설치 bs4 사용하여 html 파싱하기.</description>
    </item>
    
    <item>
      <title>구글 클라우드 펑션</title>
      <link>http://example.org/docs/develope/gcf1/</link>
      <pubDate>Mon, 04 May 2020 15:52:41 +0900</pubDate>
      
      <guid>http://example.org/docs/develope/gcf1/</guid>
      <description>구글 클라우드 펑션을 사용중.
친구랑 뭘 좀 만들어보려고하는데, 내 진도가 느리다.
어떤 펑션을 돌리는 서버를 클라우드에 올리는건데 좋네. 구글은 몬하는게 뭐니.
http 기본이 전혀 없어서 우격다짐으로 해보는중인데, ㅇㅇㅇ
&amp;ldquo;서버url&amp;rdquo;+&amp;quot;?&amp;quot;+&amp;ldquo;value=&amp;quot;+&amp;ldquo;hahaha&amp;rdquo;
이런식으로 url이 들어가면 서버는 이 클라이언트가 요청한 value 값에따라서 이런저런걸 처리하는거구나.
f-string을 사용함.
gcf에서 beautifulsoup를 import하는 방법을 찾는중이다.
그냥 requirements.txt에 적으면 deploy는 되는데 함수 실행시 에러가 난다.</description>
    </item>
    
    <item>
      <title>Insertimg</title>
      <link>http://example.org/docs/develope/insertimg/</link>
      <pubDate>Tue, 28 Apr 2020 21:47:51 +0900</pubDate>
      
      <guid>http://example.org/docs/develope/insertimg/</guid>
      <description>휴고 포스트에 이미지 넣기.
매우 쉬웠음.
static 폴더 안에 있는 이미지들은 그대로 올라감. 상대패스도 그대로.
그래서 로고이미지의 위치가 static/logo.jpg 라면
마크다운에 그냥 logo.jpg 넣고
이미지가 넘 많아질것같으니 폴더에 넣어서 관리하겠어 하면 static안에 새로운 폴더를 만들어서 거기에 넣으면 상대경로를 그대로 사용 가능.
static/image/1.png는 /image/1.png 라고 마크다운에 파일위치를 넣어주면 된다. 미리보기에서는 안됨 ㅍㅎㅎㅎ
암튼 하나 했음 별거아니지만 뿌-듯
 200814 추가
\image\1.png 는 안된다!!
헷갈리므로 조심</description>
    </item>
    
    <item>
      <title>휴고 블로그 구축과정</title>
      <link>http://example.org/docs/develope/hugo-blog/</link>
      <pubDate>Mon, 27 Apr 2020 21:37:12 +0900</pubDate>
      
      <guid>http://example.org/docs/develope/hugo-blog/</guid>
      <description>블로그 프레임웍 정하기
맨처음에는 깃헙 블로그 검색하면 한글로 가장 많이 나오는 지킬로 기본 테마만 만들고 수정할 수 없어서 몇번 만들어놓기만 하고 포기&amp;hellip;
이후 헥소라는 애를 써봄. 쉬운듯했으나 뭔가 어려웠다. 영어로 된 자료도 별로 없었음. 그래서 또 헤엄.
휴고라는 친구를 발견. 오오. 이게 요새 핫하다 이거지. 그래 정했어.
적용하고 코드도 뜯어보니 이게 그나마 낫다. 단순히 그동안의 시행착오가 누적되어 그런걸지도..
  테마 정하고
book 이라는 테마로 정함. 깔끔하네.
  커스토마이즈</description>
    </item>
    
    <item>
      <title>Fiiinally</title>
      <link>http://example.org/docs/develope/yuppppp/</link>
      <pubDate>Mon, 27 Apr 2020 21:13:13 +0900</pubDate>
      
      <guid>http://example.org/docs/develope/yuppppp/</guid>
      <description>드디어 블로그 뼈대 완성쓰 했다
Finally I finished building my blog structure using hugo :P
Took so much energy and time.
Now the document begins</description>
    </item>
    
    <item>
      <title>블로그 프레임웤 정함</title>
      <link>http://example.org/docs/develope/blogframework/</link>
      <pubDate>Wed, 22 Apr 2020 23:39:36 +0900</pubDate>
      
      <guid>http://example.org/docs/develope/blogframework/</guid>
      <description>마침내 깃헙블로그 프레임웤을 정했음.
지킬 &amp;ndash;&amp;gt; 헥소 &amp;ndash;&amp;gt; 휴고
앞에 두 개는 하나도 이해할 수 없어서 너무나 막막했기에 더 쉬운 사용성을 가진 플랫폼을 찾아다녔다
휴고는 그나마 좀 알겠다는거? 따라서 커스텀하기도 빠를것이다 하는 생각임
그래서 무슨 내용을 어떤식으로 올릴것인가.
나도모르오.</description>
    </item>
    
    <item>
      <title>xpath 사용해서 엘리먼트 찾기</title>
      <link>http://example.org/docs/develope/xpath-%EC%82%AC%EC%9A%A9%ED%95%B4%EC%84%9C-%EC%97%98%EB%A6%AC%EB%A8%BC%ED%8A%B8-%EC%B0%BE%EA%B8%B0/</link>
      <pubDate>Tue, 31 Mar 2020 23:38:45 +0000</pubDate>
      
      <guid>http://example.org/docs/develope/xpath-%EC%82%AC%EC%9A%A9%ED%95%B4%EC%84%9C-%EC%97%98%EB%A6%AC%EB%A8%BC%ED%8A%B8-%EC%B0%BE%EA%B8%B0/</guid>
      <description>xpath에 엘리먼트가 로딩(?) 될 때 까지 5초 기다림. 엘리먼트가 로드되면 esc 누름. 외국서버에 있는 홈페이진데 굳이 모든 요소가 로딩될때까지 기다릴 필요는 없으니 ㅇㅇ  WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH , &amp;quot;&amp;quot;&amp;quot; // *[@id=&amp;quot;mainContent&amp;quot;]/div/div[1]/main/div[1]/div[1]/p &amp;quot;&amp;quot;&amp;quot;)))ActionChains(driver).send_keys(Keys.ESCAPE).perform()지정한 위치(xpath)에 있는 요소를 찾음. 그리고 걔를 num_of_results라는 변수로 저장.  num_of_results= driver.find_element_by_xpath(&amp;quot;&amp;quot;&amp;quot; //*[@id=&amp;quot;mainContent&amp;quot;]/div/div[1]/main/div[1]/div[1]/p &amp;quot;&amp;quot;&amp;quot;)2번과 같이 xpath로 엘리먼트를 찾아서 info라고 정의.  info = driver.find_element_by_xpath(&amp;quot;&amp;quot;&amp;quot;//*[@id=&amp;quot;product-description-content-8&amp;quot;]/div/div&amp;quot;&amp;quot;&amp;quot;)info라는 엘리먼트 내부(.)에서 p태그를 가진 요소&amp;rsquo;들&amp;rsquo;을 모두 찾음(//p). elements이기 때문에 serving_info는 리스트임.</description>
    </item>
    
    <item>
      <title>마이프로틴 웹크롤러</title>
      <link>http://example.org/docs/develope/%EB%A7%88%EC%9D%B4%ED%94%84%EB%A1%9C%ED%8B%B4-%EC%9B%B9%ED%81%AC%EB%A1%A4%EB%9F%AC/</link>
      <pubDate>Mon, 30 Mar 2020 23:44:41 +0000</pubDate>
      
      <guid>http://example.org/docs/develope/%EB%A7%88%EC%9D%B4%ED%94%84%EB%A1%9C%ED%8B%B4-%EC%9B%B9%ED%81%AC%EB%A1%A4%EB%9F%AC/</guid>
      <description>파이썬+셀레늄을 이용해 마이프로틴 웹사이트 크롤러를 만드는 중
이전에도 크롤링 프로그램을 만들어본 적이 있으나 언제나 배보다 배꼽이 더 큰 느낌 LMAO&amp;hellip;
여튼, 이전에는 마우스 좌표도 넣어주고 하는 등 매우 허섭하게 만들었던 것 같은데
이번에는 xpath 이용해서 (제대로 된 방법인지는 모르겠으나)
그래도 나름 요소들을 최대한 골라내어 크롤링을 하려했다.
가장 중요한 교훈은
첫 정보를 긁어올 때 제대로 긁어와야 그 이후 과정이 편하다는 것.
이 테이블 값 긁어오느라 xpath 넣어줄때도 조건문도 넣고 패런츠 차일드 등등 새로운 걸 많이 알게 되었다.</description>
    </item>
    
    <item>
      <title>aint easy</title>
      <link>http://example.org/docs/develope/aint-easy/</link>
      <pubDate>Sun, 22 Mar 2020 22:19:36 +0000</pubDate>
      
      <guid>http://example.org/docs/develope/aint-easy/</guid>
      <description>building an web crawler to gather nutritional information of every products on myprotein
expected to finish by today, but didn&amp;rsquo;t go as scheduled, like everything else in our lives. LOL
but at least I&amp;rsquo;m enjoying it</description>
    </item>
    
    <item>
      <title>building a web crawler</title>
      <link>http://example.org/docs/develope/building-a-web-crawler/</link>
      <pubDate>Thu, 19 Mar 2020 23:12:54 +0000</pubDate>
      
      <guid>http://example.org/docs/develope/building-a-web-crawler/</guid>
      <description>파이썬으로 마이프로틴 홈페이지를 긁어서, 제품 DB를 만들고
내가 현재 먹고있는 영양제들을 체크하면
전체 영양소를 보여주는 걸 만들려고 한다.
먼저 크롬 크롤러부터 구축하는중.
이전에 학교 근로할 때 노가다가 귀찮아서 크롤러 만들었던게 도움이 된다.
적어도 크롤링 도구를 만들 수 있다는걸 아는게 어딘지..
Building a python web crawler (in chrome browser) since yesterday, to get nutrition information of every products of myprotein.
When someone pick currently-taking-product among product list,
it will display daily intake vitamins, proteins, or whatever in total.</description>
    </item>
    
    <item>
      <title>can a github blog substitute a paper note?</title>
      <link>http://example.org/docs/develope/finally/</link>
      <pubDate>Mon, 09 Mar 2020 21:31:31 +0000</pubDate>
      
      <guid>http://example.org/docs/develope/finally/</guid>
      <description>from what jekyll? to hexo finally.
much easier to use for newbs just like me lol
so, what do I post from now? idk</description>
    </item>
    
    <item>
      <title>haha</title>
      <link>http://example.org/docs/develope/haha/</link>
      <pubDate>Sun, 08 Mar 2020 16:40:31 +0000</pubDate>
      
      <guid>http://example.org/docs/develope/haha/</guid>
      <description>test</description>
    </item>
    
  </channel>
</rss>
